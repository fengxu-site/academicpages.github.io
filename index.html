<!DOCTYPE html>
<!-- saved from url=(0019)http://47.93.99.27/ -->
<html lang="zh-CN"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Feng Xu (徐枫) – Associate Professor of Tsinghua University</title>

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="template" content="Author 1.32">
	<meta name="generator" content="WordPress 4.7.11">
	<link rel="dns-prefetch" href="http://47.93.99.27/">
	<link rel="dns-prefetch" href="http://fonts.googleapis.com/">
	<link rel="dns-prefetch" href="http://s.w.org/">
	<link rel="alternate" type="application/rss+xml" title="Feng Xu (徐枫) » Feed" href="http://47.93.99.27/?feed=rss2">
	<link rel="alternate" type="application/rss+xml" title="Feng Xu (徐枫) » 评论Feed" href="http://47.93.99.27/?feed=comments-rss2">
	<script type="text/javascript">
        window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.2.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.2.1\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/47.93.99.27\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.7.11"}};
        !function(a,b,c){function d(a){var b,c,d,e,f=String.fromCharCode;if(!k||!k.fillText)return!1;switch(k.clearRect(0,0,j.width,j.height),k.textBaseline="top",k.font="600 32px Arial",a){case"flag":return k.fillText(f(55356,56826,55356,56819),0,0),!(j.toDataURL().length<3e3)&&(k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57331,65039,8205,55356,57096),0,0),b=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57331,55356,57096),0,0),c=j.toDataURL(),b!==c);case"emoji4":return k.fillText(f(55357,56425,55356,57341,8205,55357,56507),0,0),d=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55357,56425,55356,57341,55357,56507),0,0),e=j.toDataURL(),d!==e}return!1}function e(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var f,g,h,i,j=b.createElement("canvas"),k=j.getContext&&j.getContext("2d");for(i=Array("flag","emoji4"),c.supports={everything:!0,everythingExceptFlag:!0},h=0;h<i.length;h++)c.supports[i[h]]=d(i[h]),c.supports.everything=c.supports.everything&&c.supports[i[h]],"flag"!==i[h]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[i[h]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",g,!1),a.addEventListener("load",g,!1)):(a.attachEvent("onload",g),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);
	</script>
	<script src="./new_homepage_cssfile/wp-emoji-release.min.js" type="text/javascript" defer=""></script>
	<script src="js/mustache.min.js" type="text/javascript"></script>
	<style type="text/css">
		img.wp-smiley,
		img.emoji {
			display: inline !important;
			border: none !important;
			box-shadow: none !important;
			height: 1em !important;
			width: 1em !important;
			margin: 0 .07em !important;
			vertical-align: -0.1em !important;
			background: none !important;
			padding: 0 !important;
		}
        #paper-list {
			/*color: red;*/
		}
        .li-btn {
            display:inline; 
            float: left;
            margin-right: 1rem;
            border: 1px solid black;
            /* background-color: #808080; */
        }
        .li-btn a {
            margin: 5px;
            display:block;    /*step 3.<a>标记让其以块状显示*/
            text-decoration:none;
        }
        .li-btn a:hover
        {
        background-color:#cdcdcd;/*step 4.链接的盘旋时的样式,让其背景色高亮*/
        }
        .li-btn-on {
            background-color: #b7b7b7;
        }
	</style>
	<!--<link rel="stylesheet" id="ct-author-google-fonts-css" href="./new_homepage_cssfile/css" type="text/css" media="all">-->
	<link rel="stylesheet" id="font-awesome-css" href="./new_homepage_cssfile/font-awesome.min.css" type="text/css" media="all">
	<link rel="stylesheet" id="ct-author-style-css" href="./new_homepage_cssfile/style.css" type="text/css" media="all">
	<script type="text/javascript" src="./new_homepage_cssfile/jquery.js"></script>
	<script type="text/javascript" src="./new_homepage_cssfile/jquery-migrate.min.js"></script>
	<!--[if IE 8]>
	<script type='text/javascript' src='http://47.93.99.27/wp-content/themes/author/js/build/html5shiv.min.js?ver=4.7.11'></script>
	<![endif]-->
	<link rel="https://api.w.org/" href="http://47.93.99.27/?rest_route=/">
	<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://47.93.99.27/xmlrpc.php?rsd">
	<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://47.93.99.27/wp-includes/wlwmanifest.xml">
	<link rel="canonical" href="http://47.93.99.27/">
	<link rel="shortlink" href="http://47.93.99.27/">
	<link rel="alternate" type="application/json+oembed" href="http://47.93.99.27/?rest_route=%2Foembed%2F1.0%2Fembed&amp;url=http%3A%2F%2F47.93.99.27%2F">
	<link rel="alternate" type="text/xml+oembed" href="http://47.93.99.27/?rest_route=%2Foembed%2F1.0%2Fembed&amp;url=http%3A%2F%2F47.93.99.27%2F&amp;format=xml">
	<link rel="icon" href="http://47.93.99.27/wp-content/uploads/2018/10/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20181013124526-150x150.png" sizes="32x32">
	<link rel="icon" href="http://47.93.99.27/wp-content/uploads/2018/10/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20181013124526.png" sizes="192x192">
	<link rel="apple-touch-icon-precomposed" href="http://47.93.99.27/wp-content/uploads/2018/10/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20181013124526.png">
	<meta name="msapplication-TileImage" content="http://47.93.99.27/wp-content/uploads/2018/10/微信截图_20181013124526.png">
	<style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style></head>


<body id="author" class="home page-template-default page page-id-160 page-parent singular singular-page singular-page-160">
<a class="skip-content" href="http://47.93.99.27/#main">Skip to content</a>
<div id="overflow-container" class="overflow-container">
	<div class="max-width">
		<div id="main-sidebar" class="main-sidebar" style="position: fixed;">
			<header class="site-header" id="site-header" role="banner">
				<div id="title-container" class="title-container">
					<div id="site-avatar" class="site-avatar" style="background-image: url(&#39;images/me3.png&#39;)" title="Feng Xu (徐枫) avatar"></div>
					<div class="container">
						<div id="site-title" class="site-title"><a href=""></a>Feng Xu (徐枫)</a></div>								<p class="tagline">Associate Professor of Tsinghua University</p>							</div>
						<!-- <div id="site-title" class="site-title"><a href="http://47.93.99.27/">Feng Xu (徐枫)</a></div>								<p class="tagline">Associate Professor of Tsinghua University</p>							</div> -->
				</div>
				<button id="toggle-navigation" class="toggle-navigation" aria-expanded="false">
					<span class="screen-reader-text">open primary menu</span>
					<i class="fa fa-bars"></i>
				</button>
				<div id="menu-primary" class="menu-container menu-primary" role="navigation">
					<nav class="menu"><ul id="menu-primary-items" class="menu-primary-items">
                        <!--<li id="menu-item-163" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home current-menu-item page_item page-item-160 current_page_item menu-item-163"><a href="#News">News</a></li>-->
						<li id="menu-item-83" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-83"><a href="#About_me">About me</a></li>
						<li id="menu-item-85" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-85"><a href="#Publications">Publications</a></li>
						<li id="menu-item-151" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-151"><a href="#Patents">Patents</a></li>
						<li id="menu-item-155" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-155"><a href="#Contact_me">Contact me</a></li>
					</ul></nav></div>					</header>
		</div>
		<section id="main" class="main" role="main">
			<div id="loop-container" class="loop-container">
				<div class="post-160 page type-page status-publish hentry entry">
					<article>
						<div class="post-header">
							<!--<h1 class="post-title" id = "News">News</h1>
						</div>
						<div class="post-content">
                            <!--<p><span class="style233"><span lang="EN-US">May.&nbsp;&nbsp;2023&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>EgoLocate: Real-time Motion Capture, Localization, and Mapping with Sparse Body-mounted Sensors</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;ACM SIGGRAPH 2023.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">May.&nbsp;&nbsp;2023&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">May.&nbsp;&nbsp;2023&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">May.&nbsp;&nbsp;2023&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Learning a 3D Morphable Face Reflectance Model from Low-cost Data</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Sep.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Physical Interaction: Reconstructing Hand-object Interactions with Physics</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;ACM SIGGRAPH Asia 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Sep.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>A Digital Mask to Safeguard Patient Privacy</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;Nature Medicine 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Aug.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Deep Learning with Weak Annotation from Diagnosis reports for detection of multiple head disorders: a prospective, multicentre study</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;The Lancet Digital Health (LDH) 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Jul.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;SIGGRAPH Conference Proceedings 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Apr.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Semantically Disentangled Variational Autoencoder for Modeling 3D Facial Details</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;TVCG 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2022.</span></span></p>
                            <!--<p><p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2022&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion Tracking from Sparse Inertial Sensors</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2022.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>TransPose: Real-time 3D Human Translation and Pose Estimation with Six Inertial Sensors</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;SIGGRAPH 2021.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Monocular Real-time Full Body Capture with Inter-part Correlations</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2021.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Audio-Driven Emotional Video Portraits</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2021.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>DTexFusion: Dynamic Texture Fusion using a Consumer RGBD Sensor</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;TVCG.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Feb.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Single Depth View Based Real-time Reconstruction of Hand-objectInteractions</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;TOG.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Jan.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>A Rate-based Drone Control with Adaptive Origin Update in Telexistence</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;IEEE VR 2021.</span></span></p>
                            <!--<p><span class="style233"><span lang="EN-US">Jan.&nbsp;&nbsp;2021&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Toward human intervention-free clinical diagnosis of intracranial aneurysm via deep neural network</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;Patterns.</span></span></p>
                            <!-- <p><span class="style233"><span lang="EN-US">Oct.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Emotion-preserving Blendshape Update with Real-time Face Tracking</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;TVCG.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Aug.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Single Image Portrait Relighting via Explicit Multiple Reflectance Channel Modeling</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;Siggraph Asia 2020.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Jul.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Eyeglasses 3D shape reconstruction from a single face image</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;ECCV 2020.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Feb.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;CVPR 2020.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Jan.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Accurate Real-time 3D Gaze Tracking Using a Lightweight Eyeball Calibration</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;Eurographics 2020.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Jan.&nbsp;&nbsp;2020&nbsp; &nbsp; &nbsp; Our&nbsp;work "<strong>Data-Driven 3D Neck Modeling and Animation</strong></span></span><span class="style233"><span lang="EN-US">" was&nbsp;accepted by&nbsp;TVCG.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Jul.&nbsp;&nbsp;2019&nbsp; &nbsp; &nbsp; Our&nbsp;work “<strong>Real-time Indoor Scene Reconstruction with RGBD and Inertial Input</strong></span></span><span class="style233"><span lang="EN-US">” won&nbsp;the Best Student Paper Award&nbsp;in ICME 2019.</span></span></p>
                            <p><span class="style233"><span lang="EN-US">Apr.&nbsp;&nbsp;2019&nbsp; &nbsp; &nbsp; Our&nbsp;work “<strong>InteractionFusion: Real-time Reconstruction of Hand Poses and Deformable Objects in Hand-object Interactions</strong></span></span><span class="style233"><span lang="EN-US">” was&nbsp;accepted by&nbsp;SIGGRAPH 2019.</span></span></p>
                            <p><span class="style233"><span lang="EN-US">Mar.&nbsp;&nbsp;2019&nbsp; &nbsp; &nbsp; Our&nbsp;work “<strong>Real-time Indoor Scene Reconstruction with RGBD and Inertial Input</strong></span></span><span class="style233"><span lang="EN-US">” was&nbsp;accepted by&nbsp;ICME 2019.</span></span></p> -->
                            <!-- <p><span class="style233"><span lang="EN-US">Sep.&nbsp;&nbsp;2018&nbsp; &nbsp; &nbsp; Our&nbsp;work “<strong>DDRNet: Depth Map Denoising and Refinement for Consumer Depth Cameras Using Cascaded CNNs</strong></span></span><span class="style233"><span lang="EN-US">” was&nbsp;accepted by&nbsp;ECCV 2018.</span></span></p>
                            <p><span class="style233"><span lang="EN-US">Aug.&nbsp;&nbsp;2018&nbsp; &nbsp; &nbsp; Our&nbsp;work “<strong>Parallax360: Stereoscopic 360° Scene Representation for Head-Motion Parallax</strong></span></span><span class="style233"><span lang="EN-US">” was presented in the TVCG section of Siggraph 2018.</span></span></p> -->
                        	<!--<hr>
							 <!--<p class="style23"><strong>Academic Activities</strong></p>
							<p class="style23"><span class="style233"><span lang="EN-US">Conference Program Committee: SIGGRAPH Asia 2022, SIGGRAPH 2022, PG 2019, SCA 2019, PG 2018, SCA 2018</span></span></p>
							<p class="style23"><span class="style233"><span lang="EN-US">Paper Reviewer: Science Advances, Patterns, SIGGRAPH, SIGGRAPH ASIA, ACM TOG, CVPR, ICCV, ECCV, IEEE TPAMI, IEEE TVCG, IEEE TIP, IEEE TCSVT</span></span></p>
							<hr> -->
							<p class="style23">
							</p></div>
						<div class="post-header">
							<h1 class="post-title" id = "About_me">About me</h1>
						</div>
						<div class="post-content">
							<p><strong>Associate Professor</strong>&nbsp;in School of Software, <span style="color: #3366ff;"><a style="color: #3366ff;" href="http://www.tsinghua.edu.cn/publish/thu2018en/index.html" target="_blank" rel="noopener noreferrer">Tsinghua University</a></span>, Beijing, Chin<span class="style53">a</span></p>
							<hr>
							<p><strong>Education</strong></p>
							<ul>
								<li><strong><em><span class="style581"><span lang="EN-US">Ph.D.</span></span></em><span xml:lang="EN-US"><span lang="EN-US"><strong>&nbsp;</strong>&nbsp;</span></span></strong><span class="style233"><span xml:lang="EN-US"><span lang="EN-US">Sep. 2007 ~ July 2012, Department of Automation, Tsinghua University, Beijing, China.</span></span></span></li>
								<li><span lang="EN-US">&nbsp;</span><strong><i><span lang="EN-US">B.S.</span></i></strong><span lang="EN-US">&nbsp;<strong><span xml:lang="EN-US">&nbsp;</span></strong><span class="style233"><span xml:lang="EN-US">Sep.&nbsp;</span><span xml:lang="EN-US">2003 ~ July 2007, Department of Physics, Tsinghua University, Beijing, China.</span></span></span></li>
							</ul>
							<hr>
							<p><strong>Research Interests</strong></p>
							<ul>
								<li class="style23"><span class="style233"><span lang="EN-US">3D Vision and Graphics</span></span></li>
								<li class="style23"><span class="style233"><span lang="EN-US">Digital Health</span></span></li>
								<!--<li class="style23"><span class="style233"><span lang="EN-US"></span></span></li>-->
							</ul>
							<hr>
							<p class="style23"><strong>Academic Activities</strong></p>
							<p class="style23"><span class="style233"><span lang="EN-US">Journal AE/Conference Committee/Area Chair: TVCG, SIGGRAPH 2023, ICCV 2023, SIGGRAPH Asia 2022, SIGGRAPH 2022...</span></span></p>
							<p class="style23"><span class="style233"><span lang="EN-US">Paper Reviewer: Science Advances, Nature Aging, Patterns, SIGGRAPH, SIGGRAPH ASIA, ACM TOG, CVPR, ICCV, ECCV, IEEE TPAMI, IEEE TVCG, IEEE TIP, IEEE TCSVT</span></span></p>
							<hr>
						</div>
						<div class="post-header">
							<h1 class="post-title" id = "Publications">Publications</h1>
						</div>
                        <div class="post-content">
                            <ul style="list-style-type:none;">
                                <li id="li-all" class="li-btn li-btn-on"><a lang="EN-US">All</a></li>
								<li id="li-3d" class="li-btn"><a lang="EN-US">3D Vision and Graphics</a></li>
								<li id="li-medicine" class="li-btn"><a lang="EN-US">Digital Health</a></li>
							</ul>
                        </div>
                        <div class="post_content" id="paper-list">



						</div>
						<div class="post-header">
							<h1 class="post-title" id = "Patents">Patents</h1>
						</div>
                        <div class="post-content">
                            <p><strong><span class="style233"><span lang="EN-US">US Patents</span></span></strong></p>
                            <p><span class="style233"><span lang="EN-US">[1]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Xiang Cao,&nbsp;<span class="SpellE">Takaaki</span>&nbsp;<span class="SpellE">Shiratori</span>, Xin Tong,&nbsp;<b>Feng Xu</b>, Thomas&nbsp;<span class="SpellE">Gersten</span>,&nbsp;<span class="SpellE">Tommer</span>&nbsp;<span class="SpellE">Leyvand</span>, “Motion control of a virtual environment”, U.S. patent application filed on 19 November 2013, Appl. No.: 14/084481</span></span></p>
                            <hr>
                            <p><strong>China Patents</strong></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[1]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai,&nbsp;<b>Feng Xu</b>, “A method and System for Depth Sequence Generation”, ZL200810225515.6, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[2]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai,<b>&nbsp;Feng Xu</b>,&nbsp;<span class="SpellE">Xudong</span>,&nbsp;<span class="SpellE">Xie</span>, “A method for Depth Sequence Generation in 2D to 3D Conversion”, ZL200810103681.9, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[3]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai,&nbsp;<b>Feng Xu</b>, “A method and System for Panorama Generation based on Feature Matching”, ZL200810225431.2, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[4]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai, Wei&nbsp;<span class="SpellE">Hao</span>,&nbsp;<b>Feng Xu</b>,&nbsp;<span class="SpellE">Haoqian</span>&nbsp;Wang, “A System for Multi-view 3D Rendering”, ZL201110362615, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[5]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai,&nbsp;<b>Feng Xu</b>,&nbsp;<span class="SpellE">Haoqian</span>&nbsp;Wang, “A method and System for 3D Human model Registration”, ZL201110188565.3, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[6]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Yebin</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Liu, Kai Li,&nbsp;<span class="SpellE">Haoqian</span>&nbsp;Wang,&nbsp;<b>Feng Xu</b>,&nbsp;<span class="SpellE">Qionghai</span>&nbsp;Dai, “A method and System for Feature Motion Segmentation in Video with Large Inter-frame Motion”</span></span><span class="style233"><span lang="EN-US">, ZL201110197873.2, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[7]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="SpellE"><span class="style233"><span lang="EN-US">Qionghai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Dai,&nbsp;<b>Feng Xu</b>, “A method and System for Occlusion Handling in Video Motion Segmentation”, ZL201310394009, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[8]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><b>Feng Xu</b>,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Quan</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Wen,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Junhai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Yong, “Method and device for bidirectional sight line direction estimation based on linear regression”, ZL2017101839559, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[9]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><b>Feng Xu</b>,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Quan</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Wen,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Junhai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Yong, “Human eye sight tracking method and device based on three-dimensional spherical Taylor expansion”, ZL2017102235289, Granted</span></span></p>
                            <p class="references"><span class="style233"><span lang="EN-US">[10]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><b>Feng Xu</b>,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Bicheng</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Luo,&nbsp;<span class="SpellE"><span class="style233"><span lang="EN-US">Junhai</span></span></span><span class="style233"><span lang="EN-US">&nbsp;Yong, “Image rendering method and system”, ZL2017101839559, Granted</span></span></p>
                        </div>

						<div class="post-header">
							<h1 class="post-title" id = "Contact_me">Contact me</h1>

						</div>
						<div class="post-content">
							<!-- <p><span xml:lang="EN-US"><span lang="EN-US"><strong>Telephone</strong></span></span><em><span xml:lang="EN-US"><span lang="EN-US">:</span></span></em><span class="style44"><span xml:lang="EN-US"><span lang="EN-US">&nbsp;</span></span></span><span lang="EN-US">&nbsp;</span><span class="style91"><span xml:lang="EN-US"><span lang="EN-US">+86-10-6279-5401</span></span></span></p> -->
							<p><span xml:lang="EN-US"><span lang="EN-US"><strong>E-Mail</strong></span><em><span lang="EN-US">:&nbsp;</span></em></span><span class="style211"><span xml:lang="EN-US"><span lang="EN-US">&nbsp;</span></span></span><span class="style211"><span lang="EN-US"><a href="mailto:xufeng2003@gmail.com">xufeng2003@gmail.com</a>&nbsp;<strong>OR</strong>&nbsp;<a href="mailto:feng-xu@tsinghua.edu.cn">feng-xu@tsinghua.edu.cn</a></span></span></p>
						</div>

					</article>
				</div>
			</div>
		</section><!-- .main -->
		<footer class="site-footer" role="contentinfo">
			<div class="design-credit">
        <span>
                    </span>
			</div>
		</footer>
	</div><!-- .max-width -->
</div><!-- .overflow-container -->
<script type="text/javascript">
    /* <![CDATA[ */
    var ct_author_objectL10n = {"openPrimaryMenu":"open primary menu","closePrimaryMenu":"close primary menu","openChildMenu":"open child menu","closeChildMenu":"close child menu"};
    /* ]]> */
</script>
<script type="text/javascript" src="./new_homepage_cssfile/production.min.js"></script>
<!--[if IE 8]>
<script type='text/javascript' src='http://47.93.99.27/wp-content/themes/author/js/build/respond.min.js?ver=4.7.11'></script>
<![endif]-->
<script type="text/javascript" src="./new_homepage_cssfile/wp-embed.min.js"></script>

<script type="text/template" id="template">
	{{#papers}}
	<div class="list-item" style="display: flex; align-items: center">
		<div style="flex: 0 0 120px;">
			<img src="publications/{{year}}/{{link}}.png">
		</div>
        <div style="margin-left: 15px">
			<p>{{authors}}, 
                {{#web_link}}
                "<strong><a href="{{web_link}}" target="_blank" rel="noopener noreferrer">{{title}}</a></strong>",
                {{/web_link}}
                {{^web_link}}
                "<strong><a href="publications/{{year}}/{{link}}" target="_blank" rel="noopener noreferrer">{{title}}</a></strong>",
				{{/web_link}}
                {{journal}}
				{{#video_link}}
				(<a href="publications/{{year}}/{{video_link}}" target="_blank" rel="noopener noreferrer">Video</a>)
				{{/video_link}}
				{{#project_link}}
				(<a href="{{project_link}}" target="_blank" rel="noopener noreferrer">Project</a>)
				{{/project_link}}
				{{#other_link}}
				(<a href="{{other_link}}" target="_blank" rel="noopener noreferrer">Dataset</a>)
				{{/other_link}}
			</p>
			<!-- <p>{{authors}}, “<strong><a href="http://cgcad.thss.tsinghua.edu.cn/xufeng/{{link}}" target="_blank" rel="noopener noreferrer">{{title}}</a></strong>”,
				{{journal}}
				{{#video_link}}
				(<a href="http://cgcad.thss.tsinghua.edu.cn/xufeng/{{video_link}}" target="_blank" rel="noopener noreferrer">Video</a>)
				{{/video_link}}
				{{#project_link}}
				(<a href="http://cgcad.thss.tsinghua.edu.cn/xufeng/{{project_link}}" target="_blank" rel="noopener noreferrer">Project</a>)
				{{/project_link}}
				{{#other_link}}
				(<a href="{{other_link}}" target="_blank" rel="noopener noreferrer">Dataset</a>)
				{{/other_link}}
			</p> -->
		</div>
	</div>
	<hr>
	{{/papers}}
</script>

<script type="text/javascript">
    function cmp(a, b) { 
        return b.year - a.year;
    }

    var papers_3d = [
        {
            "year": 2024,
            "authors": "Junfeng Lyu, Feng Xu",
            "link": "AniEyelid.pdf",
            "title": "High-quality Animatable Eyelid Shapes from Lightweight Captures",
            "journal": "Proc. of SIGGRAPH Asia 2024",
            "video_link": "supp_video_final.mp4",
            "project_link": "https://github.com/StoryMY/AniEyelid",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Xin Ming, Jiawei Li, Jingwang Ling, Libo Zhang, Feng Xu",
            "link": "mx-high-quality.pdf",
            "title": "High-Quality Mesh Blendshape Generation from Face Videos via Neural Inverse Rendering",
            "journal": "Proceedings of the European Conference on Computer Vision (ECCV) 2024",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Xinyu Yi, Yuxiao Zhou, Feng Xu",
            "link": "yxy Physical Non-inertial Poser (PNP).pdf",
            "title": "Physical Non-inertial Poser (PNP): Modeling Non-inertial Effects in Sparse-inertial Human Motion Capture",
            "journal": "Proc. of SIGGRAPH 2024",
            "video_link": "yxy Physical Non-inertial Poser (PNP).mp4",
            "project_link": "https://xinyu-yi.github.io/",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Jingwang Ling, Ruihan Yu, Feng Xu, Chun Du, Shuang Zhao",
            "link": "ljw nerfemitter_pbir.pdf",
            "title": "NeRF as a Non-Distant Environment Emitter in Physics-based Inverse Rendering",
            "journal": "Proc. of SIGGRAPH 2024",
            "video_link": "ljw nerfemitter_pbir.mp4",
            "project_link": "https://nerfemitterpbir.github.io/",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Haoyu Hu, Xinyu Yi, Zhe Cao, Jun-Hai Yong, Feng Xu",
            "link": "hhy Hand-Object Interaction Controller (HOIC).pdf",
            "title": "Hand-Object Interaction Controller (HOIC): Deep Reinforcement Learning for Reconstructing Interactions with Physics",
            "journal": "Proc. of SIGGRAPH 2024",
            "video_link": "",
            "project_link": "https://github.com/hu-hy17/HOIC",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Chengxu Zuo, Yiming Wang, Lishuang Zhan, Shihui Guo, Xinyu Yi, Feng Xu, Yipeng Qin",
            "link": "yxy Loose Inertial Poser.pdf",
            "title": "Loose Inertial Poser: Motion Capture with IMU-attached Loose-Wear Jacket",
            "journal": "Computer Vision and Pattern Recognition (CVPR) 2024",
            "video_link": "yxy Loose Inertial Poser.mp4",
            "project_link": "https://xinyu-yi.github.io/",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Yuxuan Han, Junfeng Lyu, Feng Xu",
            "link": "camera_ready hyx High-Quality Facial Geometry.pdf",
            "title": "High-Quality Facial Geometry and Appearance Capture at Home",
            "journal": "Computer Vision and Pattern Recognition (CVPR) 2024",
            "video_link": "camera_ready hyx High-Quality Facial Geometry.mp4",
            "project_link": "https://yxuhan.github.io/CoRA/index.html",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Wenbin Lin, Chengwei Zheng, Jun-Hai Yong, Feng Xu",
            "link": "Relightable Avatar arXiv.pdf",
            "title": "Relightable and Animatable Neural Avatars from Videos",
            "journal": "AAAI Conference on Artificial Intelligence 2024",
            "video_link": "Relightable Avatar.mp4",
            "project_link": "https://wenbin-lin.github.io/RelightableAvatar-page/",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Chengwei Zheng, Wenbin Lin, and Feng Xu",
            "link": "zcw EditableNeRF_TPAMI.pdf",
            "title": "EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points",
            "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2024",
            "video_link": "EditableNeRF.mp4",
            "project_link": "",
            "web_link": ""
        },
        {
            "year": 2023,
            "authors": "Shaohua Pan, Qi Ma, Xinyu Yi, Weifeng Hu, Xiong Wang, Xingkang Zhou, Jijunnan Li, Feng Xu",
            "link": "Fusing Monocular Images RobustCap.pdf",
            "title": "Fusing Monocular Images and Sparse IMU Signals for Real-time Human Motion Capture",
            "journal": "Proc. of SIGGRAPH Asia 2023",
            "video_link": "Fusing Monocular Images RobustCap.mp4",
            "project_link": "https://shaohua-pan.github.io/robustcap-page/",
            "web_link": ""
        },
        {
            "year": 2023,
            "authors": "Junfeng Lyu, Feng Xu",
            "link": "RefractionGaze_ISMAR23.pdf",
            "title": "Towards Eyeglasses Refraction in Appearance-based Gaze Estimation",
            "journal": "ISMAR 2023",
            "video_link": "",
            "project_link": "https://github.com/StoryMY/RefractionGaze",
            "web_link": ""
        }, 
        {
            "year": 2023,
            "authors": "Xinyu Yi, Yuxiao Zhou, Marc Habermann, Vladislav Golyanik, Shaohua Pan, Christian Theobalt, Feng Xu",
            "link": "EgoLocate.pdf",
            "title": "EgoLocate: Real-time Motion Capture, Localization, and Mapping with Sparse Body-mounted Sensors",
            "journal": "ACM SIGGRAPH 2023",
            "video_link": "EgoLocate_large.mp4",
            "project_link": "https://xinyu-yi.github.io/EgoLocate/",
            "web_link": ""
        },
        {
            "year": 2023,
            "authors": "Jingwang Ling, Zhibo Wang, Feng Xu",
            "link": "ShadowNeuS.pdf",
            "title": "ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision",
            "journal": "IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023",
            "video_link": "[CVPR 2023] ShadowNeuS_ Neural SDF Reconstruction by Shadow Ray Supervision.mp4",
            "project_link": "https://gerwang.github.io/shadowneus/",
            "web_link": ""
        },
        {
            "year": 2023,
            "authors": "Chengwei Zheng, Wenbin Lin, Feng Xu",
            "link": "EditableNeRF.pdf",
            "title": "EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points",
            "journal": "IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023",
            "video_link": "EditableNeRF.mp4",
            "project_link": "https://chengwei-zheng.github.io/EditableNeRF/",
            "web_link": ""
        },
        {
            "year": 2023,
            "authors": "Yuxuan Han, Zhibo Wang, Feng Xu",
            "link": "hyxCVPR_2023_FaceReflecanceModel.pdf",
            "title": "Learning a 3D Morphable Face Reflectance Model from Low-cost Data",
            "journal": "IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR) 2023",
            "video_link": "cvpr23_hyx.mp4",
            "project_link": "https://yxuhan.github.io/ReflectanceMM/index.html",
            "web_link": ""
        },  
        {
            "year": 2022,
            "authors": "Chengwei Zheng, Wenbin Lin, Feng Xu",
            "link": "zcw A Self-occlusion Aware.pdf",
            "title": "A Self-occlusion Aware Lighting Model for Real-time Dynamic Reconstruction",
            "journal": "IEEE Transactions on Visualization and Computer Graphics 2022",
            "video_link": "zcw A Self-occlusion Aware.mp4",
            "project_link": "",
            "web_link": "https://ieeexplore.ieee.org/document/9783067"
        },           
        {
            "year": 2022,
            "authors": "Haoyu Hu, Xinyu Yi, Hao Zhang, Jun-Hai Yong, Feng Xu",
            "link": "Physical_Interaction__Siggraph_Asia_2022.pdf",
            "title": "Physical Interaction: Reconstructing Hand-object Interactions with Physics",
            "journal": "Proc. of SIGGRAPH Asia 2022",
            "video_link": "supplementary_video.mp4",
            "project_link": "",
        },           
        {
            "year": 2022,
            "authors": "Xinya Ji, Hang Zhou, Kaisiyuan Wang, Qianyi Wu, Wayne Wu, Feng Xu, Xun Cao",
            "link": "jxy EAMM_SIG202.pdf",
            "title": "EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model",
            "journal": "Proc. of SIGGRAPH 2022",
            "video_link": "jxyEAMM_SIG202.mp4",
            "project_link": "https://jixinya.github.io/projects/EAMM",
        }, 
        {
            "year": 2022,
            "authors": "Jingwang Ling, Zhibo Wang, Ming Lu, Quan Wang, Chen Qian, Feng Xu",
            "link": "Structure-awareEditableMorphableModel.pdf",
            "title": "Structure-aware Editable Morphable Model for 3D Facial Detail Animation and Manipulation",
            "journal": "Proceedings of the European Conference on Computer Vision (ECCV) 2022",
            "video_link": "Structure-awareEditableMorphableModel.mp4",
            "project_link": "https://github.com/gerwang/facial-detail-manipulation",
        }, 
        {
            "year": 2022,
            "authors": "Jingwang Ling, Zhibo Wang, Ming Lu, Quan Wang, Chen Qian, Feng Xu",
            "link": "ljw-TVCG_3D_Facial_Details.pdf",
            "title": "Semantically Disentangled Variational Autoencoder for Modeling 3D Facial Details",
            "journal": " IEEE Transactions on Visualization Computer Graphics (TVCG) 2022",
            "video_link": "ljw-TCCG 3D_Facial_Details.mp4",
            "project_link": "",
        }, 
        {
            "year": 2022,
            "authors": "Junfeng Lyu, Zhibo Wang, Feng Xu",
            "link": "Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data.pdf",
            "title": "Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
            "video_link": "Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data.mp4",
            "project_link": "https://github.com/StoryMY/take-off-eyeglasses/",
        },  
        {
            "year": 2022,
            "authors": "Wenbin Lin, Chengwei Zheng, Jun-Hai Yong, Feng Xu",
            "link": "OcclusionFusion.pdf",
            "title": "OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
            "video_link": "OcclusionFusion.mp4",
            "project_link": "https://wenbin-lin.github.io/OcclusionFusion/",
        }, 
        {
            "year": 2022,
            "authors": "Xinyu Yi, Yuxiao Zhou, Marc Habermann, Soshi Shimada, Vladislav Golyanik, Christian Theobalt, Feng Xu",
            "link": "pip.pdf",
            "title": "Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion Tracking from Sparse Inertial Sensors",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
            "video_link": "PIP.mp4",
            "project_link": "https://xinyu-yi.github.io/PIP/",
        },
        {
            "year": 2021,
            "authors": "Xinyu Yi, Yuxiao Zhou, Feng Xu",
            "link": "TransPose Real-time 3D Human Translation and Pose Estimation with.pdf",
            "title": "TransPose: Real-time 3D Human Translation and Pose Estimation with Six Inertial Sensors",
            "journal": "ACM SIGGRAPH 2021",
            "video_link": "TransPose Real-time 3D Human Translation and Pose Estimation with.mp4",
            "project_link": "https://xinyu-yi.github.io/TransPose/",
        },              
        {
            "year": 2021,
            "authors": "Yuxiao Zhou, Marc Habermann, Ikhsanul Habibie, Ayush Tewari, Christian Theobalt, Feng Xu",
            "link": "Monocular Real-time Full Body Capture with Inter-part Correlations.pdf",
            "title": "Monocular Real-time Full Body Capture with Inter-part Correlations",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2021",
            // "video_link": "wzb_tvcg final_supplemental.mp4",
        },         
        {
            "year": 2021,
            "authors": "Xinya Ji, Hang Zhou, Kaisiyuan Wang, Wayne Wu, Chen Change Loy, Xun Cao, Feng Xu",
            "link": "Audio-Driven Emotional Video Portraits.pdf",
            "title": "Audio-Driven Emotional Video Portraits",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2021",
            // "video_link": "wzb_tvcg final_supplemental.mp4",
        },     
        {
            "year": 2021,
            "authors": "Chengwei Zheng and Feng Xu",
            "link": "DTexFusion Dynamic Texture Fusion using a Consumer RGBD Sensor.pdf",
            "title": "DTexFusion: Dynamic Texture Fusion using a Consumer RGBD Sensor",
            "journal": "IEEE Transactions on Visualization Computer Graphics(TVCG) 2021.",
            "video_link": "DTexFusion_video.mp4",
        },
        {
            "year": 2021,
            "authors": "Hao Zhang, Yuxiao Zhou, Yifei Tian, Jun-Hai Yong, Feng Xu",
            "link": "Single Depth View Based Real-time Reconstruction of Hand-object Interactions.pdf",
            "title": "Single Depth View Based Real-time Reconstruction of Hand-object Interactions",
            "journal": "ACM Transactions on Graphics 2021.",
            "video_link": "tog2021.mp4",
        },     
        {
            "year": 2021,
            "authors": "Di Zhang, Chi-Man Pun, Yang Yang, Hao Gao, Feng Xu",
            "link": "A Rate-based Drone Control with Adaptive Origin Update in Telexistence.pdf",
            "title": "A Rate-based Drone Control with Adaptive Origin Update in Telexistence",
            "journal": "The 28th IEEE Conference on Virtual Reality, April, 2021",
            // "video_link": "wzb_tvcg final_supplemental.mp4",
        },
       
        {
            "year": 2020,
            "authors": "Zhibo Wang, Jingwang Ling, Chengzeng Feng, Ming Lu, Feng Xu",
            "link": "wzb_Emotion-preserving Blendshape Update with Real-time Face Tracking.pdf",
            "title": "Emotion-preserving Blendshape Update with Real-time Face Tracking",
            "journal": "IEEE Transactions on Visualization Computer Graphics(TVCG) 2020.",
            "video_link": "wzb_tvcg final_supplemental.mp4",
        },
        {
            "year": 2020,
            "authors": "Zhibo Wang, Xin Yu, Ming Lu, Quan Wang, Chen Qian, Feng Xu",
            "link": "wzb_Single Image Portrait Relighting via Explicit Multiple Reflectance.pdf",
            "title": "Single Image Portrait Relighting via Explicit Multiple Reflectance Channel Modeling",
            "journal": "ACM Transactions on Graphics (Siggraph Asia) 2020.",
            "project_link": "https://sireer.github.io/projects/FLM_project/",
            "other_link": "https://sireer.github.io/projects/FLM_project/",
        },
        {
            "year": 2020,
            "authors": "Yating Wang, Quan Wang, Feng Xu",
            "link": "wyt_Eyeglasses 3D shape reconstruction from a single face image.pdf",
            "title": "Eyeglasses 3D shape reconstruction from a single face image",
            "journal": "European Conference on Computer Vision(ECCV) 2020.",
            // "video_link": "wzb_sigais_paper_276_supplementary_video.mp4",
        },
        {
            "year": 2020,
            "authors": "Yuxiao Zhou, Marc Habermann, Weipeng Xu, Ikhsanul Habibie, Christian Theobalt, Feng Xu",
            "link": "Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data.pdf",
            "title": "Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2020.",
            "video_link": "zyx_cvpr_video.mp4",
            "project_link": "https://calciferzh.github.io/publications/zhou2020monocular",
        },
        {
            "year": 2020,
            "authors": "Quan Wen, Derek Bradley, Thabo Beeler, Seonwook Park, Otmar Hilliges, Jun-Hai Yong, Feng Xu",
            "link": "EG20_paper1094_3Dgaze_fin_CRC.pdf",
            "title": "Accurate Real-time 3D Gaze Tracking Using a Lightweight Eyeball Calibration",
            "journal": "Computer Graphics Forum. (Proceedings of Eurographics 2020), Volume 39, Number 2, 2020",
            "video_link": "video_v4.mp4",
            "project_link": "3Dgaze/index.html",
        },
        {
            "year": 2020,
            "authors": "Yilong Liu, Chengwei Zheng, Feng Xu, Xin Tong, Baining Guo",
            "link": "Data-Driven 3D Neck Modeling and Animation.pdf",
            "title": "Data-Driven 3D Neck Modeling and Animation",
            "journal": "IEEE Transactions on Visualization and Computer Graphics, 2020",
            "video_link": "main_demo.tvcg2019.v2.mp4",
        },
        {
            "year": 2020,
            "authors": "Chenggang Yan, Biyao Shao, Hao Zhao, Ruixin Ning, Yongdong Zhang, Feng Xu",
            "link": "3D Room Layout Estimation from a Single RGB Image.pdf",
            "title": "3D Room Layout Estimation from a Single RGB Image",
            "journal": "IEEE Transactions on Multimedia, 2020",
        },
        {
            "year": 2019,
            "authors": "Xingyu Xia, Chi-Man Pun, Di Zhang, Yang Yang, Huimin Lu, Hao Gao, Feng Xu",
            "link": "A 6-DOF Telexistence Drone Controlled by a Head Mounted Display.pdf",
            "title": "A 6-DOF Telexistence Drone Controlled by a Head Mounted Display",
            "journal": "IEEE Conference on Virtual Reality and 3D User Interfaces (VR), 2019",
        },
        {
            "year": 2019,
            "authors": "Congying Liu, Zexi Yang, Feng Xu, Junhai Yong",
            "link": "Image generation from bounding box-represented semantic labels.pdf",
            "title": "Image generation from bounding box-represented semantic labels",
            "journal": "Computers & Graphics, 2019",
        },

        {
            "year": 2019,
            "authors": "Hao Zhang, Zihao Bo, Junhai Yong, Feng Xu",
            "link": "zhang2019interaction_online.pdf",
            "title": "InteractionFusion: Real-time Reconstruction of Hand Poses and Deformable Objects in Hand-object Interactions",
            "journal": "ACM SIGGRAPH 2019.",
            "video_link": "InteractionFusion_Final_Author_0608_1.mp4",
        },
        {
            "year": 2019,
            "authors": "Zunjie Zhu, Feng Xu, Chenggang Yan, Xinhong Hao, Xiangyang Ji, Yongdong Zhang and Qionghai Dai",
            "link": "2019FastFusion.pdf",
            "title": "Real-time Indoor Scene Reconstruction with RGBD and Inertial Input",
            "journal": " IEEE ICME 2019.(Best Student Paper)",
            "video_link": "zhuzunjie_VIDEO.mp4",
            "other_link": "https://github.com/zhuzunjie17/FMDataset",
        },
        {
            "year": 2018,
            "authors": "Ming Lu, Feng Xu, Hao Zhao, Anbang Yao, Yurong Chen, Li Zhang",
            "link": "2018_Exemplar-based portrait style transfer.pdf",
            "title": "Exemplar-Based Portrait Style Transfer",
            "journal": "IEEE Access 2018.",
        },
        // {
        //     "year": 2018,
        //     "authors": "Shi Yan, Chenglei Wu, Lizhen Wang, Feng Xu, Liang An, Kaiwen Guo, Yebin Liu",
        //     "link": "DDRNet.pdf",
        //     "title": "DDRNet: Depth Map Denoising and Refinement for Consumer Depth Cameras Using Cascaded CNNs",
        //     "journal": "ECCV 2018.",
        //     "video_link": "DDRNet.mp4",
        // },
        {
            "year": 2018,
            "authors": "Feng Xu and Dayang Li",
            "link": "2018_Software Based Visual Aberration Correction for HMDs.pdf",
            "title": "Software-based Visual Aberration Correction for HMDs",
            "journal": "IEEE Virtual Reality (VR) 2018.",
            "video_link": "VisualCorrection.mp4",
        },
        {
            "year": 2018,
            "authors": "Feng Xu, Tianqi Zhao, Bicheng Luo and Qionghai Dai",
            "link": "2018_Generating VR Live Videos with Tripod Panoramic Rig.pdf",
            "title": "Generating VR Live Videos with Tripod Panoramic Rig",
            "journal": "IEEE Virtual Reality (VR) 2018.",
            "video_link": "VRrig.mp4",
        },
        {
            "year": 2018,
            "authors": "Hao Zhang and Feng Xu",
            "link": "MixedFusion-tvcg.pdf",
            "title": "MixedFusion: Real-Time Reconstruction of an Indoor Scene with Dynamic Objects",
            "journal": "IEEE Transactions on Visulization and Computer Graphics (TVCG) 2018.",
            "video_link": "MixedFusion_720p-Compressed.mp4",
        },
        {
            "year": 2018,
            "authors": "Bicheng Luo, Feng Xu, Christian Richardt and Jun-Hai Yong",
            "link": "2018_Parallax360 Stereoscopic 360 degrees Scene Representation for Head-Motion Parallax.pdf",
            "title": "Parallax360: Stereoscopic 360° Scene Representation for Head-Motion Parallax",
            "journal": "IEEE Transactions on Visualization and Computer Graphics (TVCG , Proc. of IEEE VR 2018), Volume 24, Number 4, April, 2018.",
            "video_link": "360recording.avi",
        },
        // {
        //     "year": 2018,
        //     "authors": "Kaiwen Guo, Feng Xu, Yangang Wang, Yebin Liu and Qionghai Dai",
        //     "link": "2018_Robust Non-Rigid Motion Tracking and Surface Reconstruction Using L0 Regulation.pdf",
        //     "title": "Robust Non-rigid Motion Tracking and Surface Reconstruction Using L0 Regularization",
        //     "journal": "IEEE Transactions on Visualization and Computer Graphics (TVCG), Volume 24, Number 5, May, 2018.",
        //     "video_link": "ICCV15.mp4",
        // },
        {
            "year": 2017,
            "authors": "Zunjie Zhu, Feng Xu, Chenggang Yan, Ning Li, Bingjian Gong, Yongdong Zhang, Qionghai Dai",
            "link": "Real-time indoor scene reconstruction with Manhattan.pdf",
            "title": "Real-time indoor scene reconstruction with Manhattan assumption",
            "journal": "Multimedia Tools and Applications, December, 2017",
        },
        {
            "year": 2017,
            "authors": "Quan Wen, Feng Xu, Ming Lu and Jun-Hai Yong",
            "link": "2017_Real-time 3D Eyelids Tracking from Semantic Edges-min.pdf",
            "title": "Real-time 3D Eyelids Tracking from Semantic Edges",
            "journal": "ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2017), Volume 36, Number 6, November, 2017.",
            "video_link": "eyelid.mp4",
            "project_link": "projects/realtime_3d_eyelids/index.html",
        },
        // {
        //     "year": 2017,
        //     "authors": "Tao Yu, Kaiwen Guo, Feng Xu, Yuan Dong, Zhaoqi Su, Jianhui Zhao, Jianguo Li, Qionghai Dai, Yebin Liu",
        //     "link": "2017_Yu_BodyFusion_Real-Time_Capture_ICCV_2017_paper.pdf",
        //     "title": "BodyFusion: Real-time Capture of Human Motion and Surface Geometry Using a Single Depth Camera",
        //     "journal": "IEEE International Conference on Computer Vision (ICCV), 2017.",
        //     "video_link": "BodyFusion.mp4",
        // },
        {
            "year": 2017,
            "authors": "Ming Lu, Hao Zhao, Anbang Yao, Feng Xu, Yurong Chen, and Li Zhang",
            "link": "2017_iccv2017_style.pdf",
            "title": "Decoder Network over Lightweight Reconstructed Feature for Fast Semantic Style Transfer",
            "journal": "IEEE International Conference on Computer Vision (ICCV), 2017.",
        },
        // {
        //     "year": 2017,
        //     "authors": "Kaiwen Guo, Feng Xu, Tao Yu, Xiaoyang Liu, Qionghai Dai and Yebin Liu",
        //     "link": "2017_TOG_guo.pdf",
        //     "title": "Real-time Geometry, Albedo and Motion Reconstruction Using a Single RGBD Camera",
        //     "journal": "ACM Transactions on Graphics (presented on Siggraph 2017), Volume 36, Number 3, 2017.",
        //     "video_link": "albedoFusion.mp4",
        // },
        {
            "year": 2017,
            "authors": "Quan Wen, Feng Xu, Jun-hai Yong",
            "link": "2017_Real-Time 3D Eye Performance.pdf",
            "title": "Real-time 3D Eye Performance Reconstruction for RGBD Cameras",
            "journal": "IEEE Transactions on Visulization and Computer Graphics (TVCG) Volume 23, Issue 12, 2017.",
            "video_link": "Real-time 3D Eye Performance Reconstruction for RGBD Cameras.mp4",
        },
        // {
        //     "year": 2015,
        //     "authors": "Kaiwen Guo, Feng Xu, Yangang Wang, Yebin Liu, Qionghai Dai",
        //     "link": "ICCV15.pdf",
        //     "title": "Robust Non-rigid Motion Tracking and Surface ReconstructionUsing L0 Regularization",
        //     "journal": "International Conference on Computer Vision (ICCV) 2015.",
        //     "video_link": "ICCV15.mp4",
        // },
        {
            "year": 2014,
            "authors": "Yilong Liu, Feng Xu, Jinxiang Chai, Xin Tong, Lijuan Wang, Qiang Huo",
            "link": "cameraReady_sigAsia15.pdf",
            "title": "Video-Audio Driven Real-Time Facial Animation",
            "journal": "ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2015), 34(6), November, 2015.",
        },
        {
            "year": 2014,
            "authors": "Feng Xu, Jinxiang Chai, Yilong Liu, Xin Tong",
            "link": "Controllable_Sig.pdf",
            "title": "Controllable high-fidelity facial performance transfer",
            "journal": "ACM Transaction on Graphics (Proc. of SIGGRAPH 2014), 33(4), July, 2014.",
        },
        {
            "year": 2014,
            "authors": "Xin Yu, Feng Xu, Shunli Zhang, Li Zhang",
            "link": "Deblur_TMM.pdf",
            "title": "Efficient Patch-Wise Non-Uniform Deblurring for a Single Image",
            "journal": "IEEE Transactions on Multimedia, 16(6), October, 2014.",
        },
        {
            "year": 2014,
            "authors": "Kai Li, Qionghai Dai, Ruiping Wang, Yebin Liu, Feng Xu, Jue Wang",
            "link": "ExpressionSynthesis_TMM.pdf",
            "title": "A Data-Driven Approach for Facial Expression Retargeting in Video",
            "journal": "IEEE Transactions on Multimedia, 16(2), February, 2014.",
        },
        {
            "year": 2013,
            "authors": "Yangang Wang, Jianyuan Min, Jianjie Zhang, Yebin Liu, Feng Xu, Qionghai Dai and Jinxiang Chai",
            "link": "Hand_wang_Sig.pdf",
            "title": "Video-based Hand Manipulation Capture Through Composite Motion Control",
            "journal": "ACM Transaction on Graphics (Proc. of SIGGRAPH 2013), 32(4), July, 2013.",
        },
        {
            "year": 2012,
            "authors": "Kai Li, Feng Xu, Jue Wang, Qionghai Dai, Yebin Liu",
            "link": "ExpressionSynthesis_CVPR.pdf",
            "title": "A Data-driven Approach for Facial Expression Synthesis in Video",
            "journal": "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2012.",
        },
        {
            "year": 2011,
            "authors": "Feng Xu, Yebin Liu, Carsten Stoll, James Tompkin, Gaurav Bharaj, Qionghai Dai, Hans-Peter Seidel, Jan Kautz and Christian Theobalt",
            "link": "VBC_Sig.pdf",
            "title": "Video-based Characters – Creating New Human Performances from a Multi-view Video Database",
            "journal": "ACM Transaction on Graphics (Prof. of SIGGRAPH 2011), 30(4), August, 2011.",
        },
        {
            "year": 2011,
            "authors": "Feng Xu and Qionghai Dai",
            "link": "MonSeg_IP_fromIEEE.pdf",
            "title": "Occlusion-Aware Motion Layer Extraction under Large inter-Frame Motions",
            "journal": "IEEE Transactions on Image Processing, 20(9), September 2011.",
        },
        {
            "year": 2011,
            "authors": "Feng Xu, Kin-Man Lam and Qionghai Dai",
            "link": "seg_3D_IVC_fromELSEVIER.pdf",
            "title": "Video-object segmentation and 3D-trajectory estimation for monocular video sequences",
            "journal": "Image and Vision Computing, 29(2-3), February, 2011.",
        },
        {
            "year": 2011,
            "authors": "Mian Ma, Feng Xu, Qionghai Dai, Yebin Liu",
            "link": "animation_3DIMG.pdf",
            "title": "Animation of 3D characters from single depth camera",
            "journal": "International Conference on 3D Imaging, 2011(Oral).",
        },
        {
            "year": 2010,
            "authors": "Youwei Yan, Feng Xu, Qionghai Dai, Xiaodong Liu",
            "link": "2Dto3D_youwei_3DTV_fromIEEE.pdf",
            "title": "A novel method for automatic 2D-to-3D video conversion",
            "journal": "3DTV, 2010.",
        },
        {
            "year": 2008,
            "authors": "Feng Xu, Guihua Er, Xudong Xie and Qionghai Dai",
            "link": "2Dto3D_3DTV_fromIEEE.pdf",
            "title": "2D-to-3D Conversion Based on Motion and Color Mergence",
            "journal": "3DTV, 2008 (Oral).",
        },
        {
            "year": 2008,
            "authors": "Xudong Xie, Jie Gong, Qionghai Dai, Feng Xu",
            "link": "VIE_fromIEEE.pdf",
            "title": "Rotation and scaling invariant texture classification based on Gabor wavelets",
            "journal": "5th International Conference on VIE, 2008.",
        }
    ].sort(cmp);

    var papers_medicine = [
        {
            "year": 2024,
            "authors": "Zhanping Zhou, Yuchen Guo, Ruijie Tang, Hengrui Liang, Jianxing He, Feng Xu",
            "link": "zzp Privacy enhancing and generalizable deep npj.pdf",
            "title": "Privacy enhancing and generalizable deep learning with synthetic data for mediastinal neoplasm diagnosis",
            "journal": "NPJ Digital Medicine 2024",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Aohan Liu, Yuchen Guo, Jun-Hai Yong, and Feng Xu",
            "link": "lah Multi-Grained Radiology Report.pdf",
            "title": "Multi-grained Radiology Report Generation with Sentence-level Image-language Contrastive Learning",
            "journal": "IEEE Transactions on Medical Imaging (2024)",
            "video_link": "",
            "project_link": "https://github.com/liuaohanjsj/SILC",
            "web_link": ""
        },
        {
            "year": 2024,
            "authors": "Yuwei He, Yuchen Guo, Jinhao Lyu, Liangdi Ma, Haotian Tan, Wei Zhang, Guiguang Ding, Hengrui Liang, Jianxing He, Xin Lou, Qionghai Dai, and Feng Xu",
            "link": "mld Disorder-Free Data.pdf",
            "title": "Disorder-Free Data Are All You Need — Inverse Supervised Learning for Broad-Spectrum Head Disorder Detection",
            "journal": " NEJM AI 2024",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        }, 
        {
            "year": 2023,
            "authors": "Liangdi Ma, Jun Zhao, Guoxin Wang, Yuchen Guo, Feng Xu",
            "link": "Multi-modal Contrastive.pdf",
            "title": "Multi-modal Contrastive-Generative Pre-training for Fine-grained Skin Disease Diagnosis",
            "journal": " IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        }, 
        {
            "year": 2023,
            "authors": "Ruijie Tang, Hengrui Liang, Yuchen Guo, Zhigang Li, Zhichao Liu, Xu Lin, Zeping Yan, Jun Liu, Xin Xu, et al.",
            "link": "Pan-mediastinal neoplasm.pdf",
            "title": "Pan-mediastinal neoplasm diagnosis via nationwide federated learning: a multicentre cohort study",
            "journal": " Lacent Digital Health 2023",
            "video_link": "Pan-mediastinal neoplasm.mp4",
            "project_link": "",
            "web_link": ""
        }, 
        {
            "year": 2023,
            "authors": "Aohan Liu, Yuchen Guo, Jinhao Lyu, Jing Xie, Feng Xu, Xin Lou, Jun-hai Yong, Qionghai Dai",
            "link": "Automatic intracranial abnormality.pdf",
            "title": "Automatic intracranial abnormality detection and localization in head CT scans by learning from free-text reports",
            "journal": "Cell Reports Medicine 2023",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        }, 
        
        {
            "year": 2023,
            "authors": "Zi-Hao Bo, Yuchen Guo, Jinhao Lyu, Hengrui Liang, Jianxing He, Shijie Deng, Feng Xu, Xin Lou and Qionghai Dai",
            "link": "RelayLearning-article.pdf",
            "title": "Relay Learning: a Physically Secure Framework for Clinical Multi-site Deep Learning",
            "journal": "NPJ Digital Medicine 2023",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        }, 
        {
            "year": 2022,
            "authors": "Zhanping Zhou, Chenyang Zhao, Hui Qiao, Ming Wang, Yuchen Guo, Qian Wang, Rui Zhang, Huaiyu Wu, Fajin Dong, Zhenhong Qi, Jianchu Li, Xinping Tian, Xiaofeng Zeng, Yuxin Jiang, Feng Xu, Qionghai Dai, and Meng Yang",
            "link": "RATING Medical knowledge-guided.pdf",
            "title": "RATING: Medical knowledge-guided rheumatoid arthritis assessment from multimodal ultrasound images via deep learning",
            "journal": " Patterns, Volume 3, Issue 10, 14 October 2022",
            "video_link": "",
            "project_link": "",
            "web_link": ""
        }, 
        {
            "year": 2022,
            "authors": "Yahan Yang, Junfeng Lyu, Ruixin Wang, Quan Wen, Lanqin Zhao, Wenben Chen, Shaowei Bi, Jie Meng, Keli Mao, et al.",
            "link": "NMED.pdf",
            "title": "A Digital Mask to Safeguard Patient Privacy",
            "journal": "Nature Medicine 2022",
            "video_link": "",
            "project_link": "",
            "web_link": "https://www.nature.com/articles/s41591-022-01966-1"
        }, 
        {
            "year": 2022,
            "authors": "Yuchen Guo, Yuwei He, Jinhao Lyu, Zhanping Zhou, Dong Yang, Liangdi Ma, Haotian Tan, Changjian Chen, Wei Zhang, Jianxing Hu, Dongshan Han, Guiguang Ding, Shixia Liu, Hui Qiao, Feng Xu, Xin Lou, and Qionghai Dai",
            "link": "hyw rolo.pdf",
            "title": "Deep Learning with Weak Annotation from Diagnosis reports for detection of multiple head disorders: a prospective, multicentre study",
            "journal": "The Lancet Digital Health (LDH) 2022",
            "video_link": "hyw_rolo.mp4",
            "project_link": "https://github.com/HeYuwei/AutoHeadCAD",
            "web_link": "https://www.sciencedirect.com/science/article/pii/S2589750022000905"
        }, 
        {
            "year": 2021,
            "authors": "Zi-Hao Bo, Hui Qiao, Chong Tian, Yuchen Guo, Wuchao Li, Tiantian Liang, Dongxue Li, Dan Liao, Xianchun Zeng, Leilei Mei, Tianliang Shi, Bo Wu, Chao Huang, Lu Liu, Can Jin, Qiping Guo, Jun-Hai Yong, Feng Xu, Tijiang Zhang, Rongpin Wang, Qionghai Dai",
            "link": "Toward human intervention-free clinical diagnosis of intracranial aneurysm via deep neural network.pdf",
            "title": "Toward human intervention-free clinical diagnosis of intracranial aneurysm via deep neural network",
            "journal": "Patterns, Volume 2, Issue 2, 12 February 2021",
            // "video_link": "wzb_tvcg final_supplemental.mp4",
        }
    ].sort(cmp);

    var papers_all = papers_3d.concat(papers_medicine).sort(cmp);

    document.body.onload = generateDynamicTable(papers_all);

    function generateDynamicTable(papers) {
        let template = document.getElementById('template').innerHTML.trim();
        let paperList = document.getElementById("paper-list");
        paperList.innerHTML = Mustache.render(template, {papers: papers});
    }

    document.getElementById('li-all').addEventListener('click', function() {
        generateDynamicTable(papers_all);

        document.getElementById('li-all').className = "li-btn li-btn-on";
        document.getElementById('li-3d').className = "li-btn";
        document.getElementById('li-medicine').className  = "li-btn";
    })

    document.getElementById('li-3d').addEventListener('click', function() {
        generateDynamicTable(papers_3d);
        document.getElementById('li-all').className  = "li-btn";
        document.getElementById('li-3d').className = "li-btn li-btn-on";
        document.getElementById('li-medicine').className = "li-btn";
    })

    document.getElementById('li-medicine').addEventListener('click', function() {
        generateDynamicTable(papers_medicine);
        document.getElementById('li-all').className = "li-btn";
        document.getElementById('li-medicine').className = "li-btn li-btn-on";
        document.getElementById('li-3d').className = "li-btn";
    })

</script>

</body></html>